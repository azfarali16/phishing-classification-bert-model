{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9999396,"sourceType":"datasetVersion","datasetId":6154717}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\n\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:27:11.306763Z","iopub.execute_input":"2024-12-15T10:27:11.307447Z","iopub.status.idle":"2024-12-15T10:27:11.316700Z","shell.execute_reply.started":"2024-12-15T10:27:11.307391Z","shell.execute_reply":"2024-12-15T10:27:11.315279Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/phishing-dataset/combined_data.csv\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/phishing-dataset/combined_data.csv\",dtype={6: str})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:27:11.318576Z","iopub.execute_input":"2024-12-15T10:27:11.319132Z","iopub.status.idle":"2024-12-15T10:27:15.195841Z","shell.execute_reply.started":"2024-12-15T10:27:11.319076Z","shell.execute_reply":"2024-12-15T10:27:15.194736Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"data.dtypes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:27:15.198641Z","iopub.execute_input":"2024-12-15T10:27:15.199013Z","iopub.status.idle":"2024-12-15T10:27:15.208152Z","shell.execute_reply.started":"2024-12-15T10:27:15.198980Z","shell.execute_reply":"2024-12-15T10:27:15.207093Z"}},"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"sender      object\nreceiver    object\ndate        object\nsubject     object\nbody        object\nlabel        int64\nurls        object\ndtype: object"},"metadata":{}}],"execution_count":56},{"cell_type":"code","source":"data['text'] = data['subject']+\" \" + data['body']\n\ncols_to_keep = ['text','label']\ndata = data[cols_to_keep]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:27:15.209581Z","iopub.execute_input":"2024-12-15T10:27:15.209929Z","iopub.status.idle":"2024-12-15T10:27:15.565566Z","shell.execute_reply.started":"2024-12-15T10:27:15.209897Z","shell.execute_reply":"2024-12-15T10:27:15.564391Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"data.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:27:15.568089Z","iopub.execute_input":"2024-12-15T10:27:15.568656Z","iopub.status.idle":"2024-12-15T10:27:15.610952Z","shell.execute_reply.started":"2024-12-15T10:27:15.568602Z","shell.execute_reply":"2024-12-15T10:27:15.609525Z"}},"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"text     952\nlabel      0\ndtype: int64"},"metadata":{}}],"execution_count":58},{"cell_type":"code","source":"data.dropna(inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:27:15.612684Z","iopub.execute_input":"2024-12-15T10:27:15.613126Z","iopub.status.idle":"2024-12-15T10:27:15.671676Z","shell.execute_reply.started":"2024-12-15T10:27:15.613090Z","shell.execute_reply":"2024-12-15T10:27:15.670609Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"data_subset = data.sample(n=1000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:27:15.673284Z","iopub.execute_input":"2024-12-15T10:27:15.673767Z","iopub.status.idle":"2024-12-15T10:27:15.685801Z","shell.execute_reply.started":"2024-12-15T10:27:15.673717Z","shell.execute_reply":"2024-12-15T10:27:15.684514Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"data_subset.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:27:15.687603Z","iopub.execute_input":"2024-12-15T10:27:15.688104Z","iopub.status.idle":"2024-12-15T10:27:15.706461Z","shell.execute_reply.started":"2024-12-15T10:27:15.688051Z","shell.execute_reply":"2024-12-15T10:27:15.705137Z"}},"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"                                                     text  label\n51653   cad 9 mm received this afternoon by cibc ( our...      0\n135111  Re: TTSynth Is Available Again What does one d...      0\n33042   Re: \\nWhy do you say you love me, if you are o...      1\n62384   are you listed in major search engines ? submi...      1\n15565   CNN.com Daily Top 10 >+=+=+=+=+=+=+=+=+=+=+=+=...      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>51653</th>\n      <td>cad 9 mm received this afternoon by cibc ( our...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>135111</th>\n      <td>Re: TTSynth Is Available Again What does one d...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>33042</th>\n      <td>Re: \\nWhy do you say you love me, if you are o...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>62384</th>\n      <td>are you listed in major search engines ? submi...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15565</th>\n      <td>CNN.com Daily Top 10 &gt;+=+=+=+=+=+=+=+=+=+=+=+=...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":61},{"cell_type":"markdown","source":"## TEXT PREPROCESSING","metadata":{}},{"cell_type":"code","source":"import re","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:27:15.708125Z","iopub.execute_input":"2024-12-15T10:27:15.708604Z","iopub.status.idle":"2024-12-15T10:27:15.719040Z","shell.execute_reply.started":"2024-12-15T10:27:15.708552Z","shell.execute_reply":"2024-12-15T10:27:15.717753Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"def clean_email_text(text):\n    text = text.lower()\n\n    #remove re:\n    text = re.sub(r're:','',text)\n    \n    # htmltags\n    text = re.sub(r'<.*?>', '', text)\n    #url\n    text = re.sub(r'http[s]?://\\S+|www\\.\\S+|/[\\w/.-]+', '<link>', text)\n    \n    #email\n    text = text.replace('[@]', '@').replace('[dot]', '.')\n    text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', '<email>', text)\n    \n    #signoff\n    text = re.sub(r'\\b(best regards|regards|sincerely|thanks|thank you|kind regards|warm regards|best wishes|yours truly|yours sincerely|with appreciation|with best wishes|cheers|all the best|take care|thanks in advance|many thanks|looking forward to hearing from you|best|warmly|thanks again|gratefully|respectfully|have a great day|until next time|peace)[\\s\\S]*$', '', text)\n    \n    #removing everything but alphanumeric..\n    text = re.sub(r'[^a-zA-Z0-9\\s]|<link>|<email>', '', text)\n\n    #removing whitespaces\n    text = re.sub(r'\\s+', ' ', text).strip()\n    \n\n    return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:30:06.998529Z","iopub.execute_input":"2024-12-15T10:30:06.999051Z","iopub.status.idle":"2024-12-15T10:30:07.007931Z","shell.execute_reply.started":"2024-12-15T10:30:06.998994Z","shell.execute_reply":"2024-12-15T10:30:07.005976Z"}},"outputs":[],"execution_count":89},{"cell_type":"code","source":"data_subset['text'] = data_subset['text'].apply(clean_email_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:30:07.203123Z","iopub.execute_input":"2024-12-15T10:30:07.203546Z","iopub.status.idle":"2024-12-15T10:30:07.426651Z","shell.execute_reply.started":"2024-12-15T10:30:07.203512Z","shell.execute_reply":"2024-12-15T10:30:07.425550Z"}},"outputs":[],"execution_count":90},{"cell_type":"code","source":"data_subset.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:30:07.973441Z","iopub.execute_input":"2024-12-15T10:30:07.973839Z","iopub.status.idle":"2024-12-15T10:30:07.985067Z","shell.execute_reply.started":"2024-12-15T10:30:07.973807Z","shell.execute_reply":"2024-12-15T10:30:07.983605Z"}},"outputs":[{"execution_count":91,"output_type":"execute_result","data":{"text/plain":"                                                     text  label\n51653   cad 9 mm received this afternoon by cibc our b...      0\n135111  ttsynth is available again what does one do if...      0\n33042   why do you say you love me if you are only goi...      1\n62384   are you listed in major search engines submitt...      1\n15565   cnncom daily top 10 the daily top 10 from cnnc...      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>51653</th>\n      <td>cad 9 mm received this afternoon by cibc our b...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>135111</th>\n      <td>ttsynth is available again what does one do if...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>33042</th>\n      <td>why do you say you love me if you are only goi...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>62384</th>\n      <td>are you listed in major search engines submitt...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15565</th>\n      <td>cnncom daily top 10 the daily top 10 from cnnc...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":91},{"cell_type":"code","source":"# clean_email_text()\n# data.iloc[2]['text']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:29:41.364120Z","iopub.execute_input":"2024-12-15T10:29:41.364582Z","iopub.status.idle":"2024-12-15T10:29:41.370041Z","shell.execute_reply.started":"2024-12-15T10:29:41.364538Z","shell.execute_reply":"2024-12-15T10:29:41.368534Z"}},"outputs":[],"execution_count":83},{"cell_type":"markdown","source":"## FINETUNING","metadata":{}},{"cell_type":"code","source":"!pip install transformers torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:29:42.507226Z","iopub.execute_input":"2024-12-15T10:29:42.507669Z","iopub.status.idle":"2024-12-15T10:29:52.847800Z","shell.execute_reply.started":"2024-12-15T10:29:42.507637Z","shell.execute_reply":"2024-12-15T10:29:52.846357Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0+cpu)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}],"execution_count":84},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:52:24.472004Z","iopub.execute_input":"2024-12-15T10:52:24.472500Z","iopub.status.idle":"2024-12-15T10:52:41.301989Z","shell.execute_reply.started":"2024-12-15T10:52:24.472463Z","shell.execute_reply":"2024-12-15T10:52:41.300278Z"}},"outputs":[],"execution_count":112},{"cell_type":"code","source":"model_path = 'bert-base-uncased'\n\nmodel = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=2)\ntokenizer = AutoTokenizer.from_pretrained(model_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:29:52.859825Z","iopub.execute_input":"2024-12-15T10:29:52.860238Z","iopub.status.idle":"2024-12-15T10:29:53.289044Z","shell.execute_reply.started":"2024-12-15T10:29:52.860164Z","shell.execute_reply":"2024-12-15T10:29:53.287848Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}],"execution_count":86},{"cell_type":"code","source":"tokenizer.encode_plus(\n    data_subset.iloc[0]['text'],\n    add_special_tokens=True,\n    max_length=64,\n    padding='max_length',\n    truncation=True,\n    return_tensors='pt'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:39:35.030853Z","iopub.execute_input":"2024-12-15T10:39:35.031996Z","iopub.status.idle":"2024-12-15T10:39:35.041492Z","shell.execute_reply.started":"2024-12-15T10:39:35.031944Z","shell.execute_reply":"2024-12-15T10:39:35.040130Z"}},"outputs":[{"execution_count":104,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [101, 28353, 1023, 3461, 2363, 2023, 5027, 2011, 25022, 9818, 2256, 2924, 2012, 2055, 1016, 2753, 7610, 2057, 2074, 2288, 26828, 1037, 2261, 2781, 3283, 2057, 2024, 2145, 12422, 2004, 2205, 2339, 1996, 8536, 1042, 10139, 3643, 3058, 2005, 14666, 2001, 2005, 2651, 2130, 2295, 2017, 2741, 14666, 2041, 2006, 2322, 16215, 5863, 4372, 4948, 5356, 2968, 1998, 2115, 10112, 13066, 2031, 2042, 6727, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}],"execution_count":104},{"cell_type":"code","source":"tokenizer.encode_plus(\n    data_subset.iloc[0]['text'],\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:38:23.132465Z","iopub.execute_input":"2024-12-15T10:38:23.132834Z","iopub.status.idle":"2024-12-15T10:38:23.142349Z","shell.execute_reply.started":"2024-12-15T10:38:23.132804Z","shell.execute_reply":"2024-12-15T10:38:23.140727Z"}},"outputs":[{"execution_count":101,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [101, 28353, 1023, 3461, 2363, 2023, 5027, 2011, 25022, 9818, 2256, 2924, 2012, 2055, 1016, 2753, 7610, 2057, 2074, 2288, 26828, 1037, 2261, 2781, 3283, 2057, 2024, 2145, 12422, 2004, 2205, 2339, 1996, 8536, 1042, 10139, 3643, 3058, 2005, 14666, 2001, 2005, 2651, 2130, 2295, 2017, 2741, 14666, 2041, 2006, 2322, 16215, 5863, 4372, 4948, 5356, 2968, 1998, 2115, 10112, 13066, 2031, 2042, 6727, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}],"execution_count":101},{"cell_type":"markdown","source":"## custom class","metadata":{"execution":{"iopub.status.busy":"2024-12-15T10:30:36.678352Z","iopub.execute_input":"2024-12-15T10:30:36.678744Z","iopub.status.idle":"2024-12-15T10:30:36.684499Z","shell.execute_reply.started":"2024-12-15T10:30:36.678711Z","shell.execute_reply":"2024-12-15T10:30:36.682969Z"}}},{"cell_type":"code","source":"class PhishingDataset(Dataset):\n\n    def __init__(self,texts,lables,tokenizer,max_length=512):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self,idx):\n        text = self.texts[idx]\n        label = self.labels[idx]\n\n        encoding = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_length,\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n\n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'labels': torch.tensor(label, dtype=torch.long)\n        }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:45:22.046289Z","iopub.execute_input":"2024-12-15T10:45:22.046746Z","iopub.status.idle":"2024-12-15T10:45:22.055801Z","shell.execute_reply.started":"2024-12-15T10:45:22.046707Z","shell.execute_reply":"2024-12-15T10:45:22.054281Z"}},"outputs":[],"execution_count":105},{"cell_type":"markdown","source":"## dataset creations","metadata":{}},{"cell_type":"code","source":"texts = data_subset['text'].tolist()\nlabels = data_subset['label'].tolist()\n\n#spliting train 80% test 10% val 10%\ntrain_texts, temp_texts, train_labels, temp_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)\nval_texts, test_texts, val_labels, test_labels = train_test_split(temp_texts, temp_labels, test_size=0.5, random_state=42)\n\n#creating datasetclass\ntrain_dataset = PhishingDataset(train_texts, train_labels, tokenizer, max_length=256)\nval_dataset = PhishingDataset(val_texts, val_labels, tokenizer, max_length=256)\ntest_dataset = PhishingDataset(test_texts, test_labels, tokenizer, max_length=256)\n\n#creating batches = 32\ntrain_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=32)\ntest_dataloader = DataLoader(test_dataset, batch_size=32)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T11:01:17.045868Z","iopub.execute_input":"2024-12-15T11:01:17.046879Z","iopub.status.idle":"2024-12-15T11:01:17.055783Z","shell.execute_reply.started":"2024-12-15T11:01:17.046838Z","shell.execute_reply":"2024-12-15T11:01:17.054429Z"}},"outputs":[],"execution_count":122},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T11:02:10.896132Z","iopub.execute_input":"2024-12-15T11:02:10.897398Z","iopub.status.idle":"2024-12-15T11:02:10.968612Z","shell.execute_reply.started":"2024-12-15T11:02:10.897346Z","shell.execute_reply":"2024-12-15T11:02:10.966910Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[127], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m800\u001b[39;49m\u001b[43m]\u001b[49m\n","Cell \u001b[0;32mIn[105], line 14\u001b[0m, in \u001b[0;36mPhishingDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m,idx):\n\u001b[0;32m---> 14\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     15\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx]\n\u001b[1;32m     17\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[1;32m     18\u001b[0m         text,\n\u001b[1;32m     19\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m         return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     24\u001b[0m     )\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"],"ename":"IndexError","evalue":"list index out of range","output_type":"error"}],"execution_count":127},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}