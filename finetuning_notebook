{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9999396,"sourceType":"datasetVersion","datasetId":6154717},{"sourceId":10210103,"sourceType":"datasetVersion","datasetId":6310328}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport re\nimport time\nimport shutil\n\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:28.177028Z","iopub.execute_input":"2025-01-27T00:45:28.177373Z","iopub.status.idle":"2025-01-27T00:45:28.506491Z","shell.execute_reply.started":"2025-01-27T00:45:28.177341Z","shell.execute_reply":"2025-01-27T00:45:28.505587Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/ready-for-tuning/ready_for_tuning.csv\n/kaggle/input/phishing-dataset/combined_data.csv\n/kaggle/input/modified-dataset/modified_dataset.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# data = pd.read_csv(\"/kaggle/input/phishing-dataset/combined_data.csv\",dtype={6: str})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:28.507790Z","iopub.execute_input":"2025-01-27T00:45:28.508205Z","iopub.status.idle":"2025-01-27T00:45:28.512036Z","shell.execute_reply.started":"2025-01-27T00:45:28.508175Z","shell.execute_reply":"2025-01-27T00:45:28.511203Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# data.dtypes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:28.513110Z","iopub.execute_input":"2025-01-27T00:45:28.513708Z","iopub.status.idle":"2025-01-27T00:45:28.525642Z","shell.execute_reply.started":"2025-01-27T00:45:28.513669Z","shell.execute_reply":"2025-01-27T00:45:28.524748Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# data['text'] = data['subject']+\" \" + data['body']\n\n# cols_to_keep = ['text','label']\n# data = data[cols_to_keep]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:28.527265Z","iopub.execute_input":"2025-01-27T00:45:28.527520Z","iopub.status.idle":"2025-01-27T00:45:28.535414Z","shell.execute_reply.started":"2025-01-27T00:45:28.527496Z","shell.execute_reply":"2025-01-27T00:45:28.534620Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# data.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:28.536492Z","iopub.execute_input":"2025-01-27T00:45:28.536825Z","iopub.status.idle":"2025-01-27T00:45:28.547433Z","shell.execute_reply.started":"2025-01-27T00:45:28.536770Z","shell.execute_reply":"2025-01-27T00:45:28.546800Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# data.dropna(inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:28.548493Z","iopub.execute_input":"2025-01-27T00:45:28.548823Z","iopub.status.idle":"2025-01-27T00:45:28.560061Z","shell.execute_reply.started":"2025-01-27T00:45:28.548770Z","shell.execute_reply":"2025-01-27T00:45:28.559204Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# # data_subset = data.sample(n=3000)\n\n# data_subset = data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:28.561050Z","iopub.execute_input":"2025-01-27T00:45:28.561320Z","iopub.status.idle":"2025-01-27T00:45:28.570733Z","shell.execute_reply.started":"2025-01-27T00:45:28.561294Z","shell.execute_reply":"2025-01-27T00:45:28.570035Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# data_subset.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:28.571625Z","iopub.execute_input":"2025-01-27T00:45:28.571884Z","iopub.status.idle":"2025-01-27T00:45:28.579849Z","shell.execute_reply.started":"2025-01-27T00:45:28.571860Z","shell.execute_reply":"2025-01-27T00:45:28.579204Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"### TEXT PREPROCESSING","metadata":{}},{"cell_type":"markdown","source":"# ENGLISH ONLY","metadata":{}},{"cell_type":"code","source":"# !pip install langdetect","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:28.580708Z","iopub.execute_input":"2025-01-27T00:45:28.580997Z","iopub.status.idle":"2025-01-27T00:45:28.591743Z","shell.execute_reply.started":"2025-01-27T00:45:28.580973Z","shell.execute_reply":"2025-01-27T00:45:28.590949Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"\n# import logging\n# from langdetect import detect, LangDetectException\n\n# def is_english(text):\n#     try:\n#         if len(text.strip()) == 0:\n#             raise ValueError(\"Text is empty or too short to detect language\")\n        \n\n#         return detect(text) == 'en'\n#     except LangDetectException:\n#         print(\"Error: Unable to detect language for following text.\")\n#         print(text)\n#         return False \n#     except ValueError as e:\n#         print(f\"Error: {e}\")\n#         return False\n\n# data_subset['is_english'] = data_subset['text'].apply(is_english)\n# print('done!')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:28.594105Z","iopub.execute_input":"2025-01-27T00:45:28.594353Z","iopub.status.idle":"2025-01-27T00:45:28.601485Z","shell.execute_reply.started":"2025-01-27T00:45:28.594330Z","shell.execute_reply":"2025-01-27T00:45:28.600576Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# df = pd.read_csv('/kaggle/input/modified-dataset/modified_dataset.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:28.602503Z","iopub.execute_input":"2025-01-27T00:45:28.602759Z","iopub.status.idle":"2025-01-27T00:45:28.611872Z","shell.execute_reply.started":"2025-01-27T00:45:28.602736Z","shell.execute_reply":"2025-01-27T00:45:28.611007Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# df = df[df['is_english']==True]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:28.612836Z","iopub.execute_input":"2025-01-27T00:45:28.613083Z","iopub.status.idle":"2025-01-27T00:45:28.621229Z","shell.execute_reply.started":"2025-01-27T00:45:28.613059Z","shell.execute_reply":"2025-01-27T00:45:28.620408Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# def clean_email_text(text):\n#     text = text.lower()\n\n#     #remove re:\n#     text = re.sub(r're:','',text,flags=re.IGNORECASE)\n    \n#     # htmltags\n#     text = re.sub(r'<.*?>', '', text, flags=re.IGNORECASE)\n#     #url\n#     text = re.sub(r'http[s]?://\\S+|www\\.\\S+|/[\\w/.-]+', '<link>', text, flags=re.IGNORECASE)\n    \n#     #email\n#     text = text.replace('[@]', '@').replace('[dot]', '.',)\n#     text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', '<email>', text, flags=re.IGNORECASE)\n    \n#     #signoff\n#     text = re.sub(r'\\b(best regards|regards|sincerely|thanks|thank you|kind regards|warm regards|best wishes|yours truly|yours sincerely|with appreciation|with best wishes|cheers|all the best|take care|thanks in advance|many thanks|looking forward to hearing from you|best|warmly|thanks again|gratefully|respectfully|have a great day|until next time|peace)[\\s\\S]*$', '', text, flags=re.IGNORECASE)\n    \n#     #removing everything but alphanumeric..\n#     # text = re.sub(r'[^a-zA-Z0-9\\s.,]|<link>|<email>', '', text)\n#     # text = re.sub(r'(?!(<link>|<email>))[^a-zA-Z0-9\\s.,]', '', text, flags=re.IGNORECASE)\n\n#     text = re.sub('<link>','linkplaceholer',text, flags=re.IGNORECASE)\n#     text = re.sub('<email>','emailplaceholer',text, flags=re.IGNORECASE)\n    \n#     text = re.sub(r'[^a-zA-Z0-9\\s.,]', '', text, flags=re.IGNORECASE)\n    \n#     text = re.sub('linkplaceholer','<link>',text, flags=re.IGNORECASE)\n#     text = re.sub('emailplaceholer','<email>',text, flags=re.IGNORECASE)\n\n\n    \n#     #removing whitespaces\n#     text = re.sub(r'\\s+', ' ', text, flags=re.IGNORECASE).strip()\n    \n\n#     return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:28.622148Z","iopub.execute_input":"2025-01-27T00:45:28.622384Z","iopub.status.idle":"2025-01-27T00:45:28.631111Z","shell.execute_reply.started":"2025-01-27T00:45:28.622362Z","shell.execute_reply":"2025-01-27T00:45:28.630288Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# df['text'] = df['text'].apply(clean_email_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:28.632134Z","iopub.execute_input":"2025-01-27T00:45:28.632365Z","iopub.status.idle":"2025-01-27T00:45:28.643984Z","shell.execute_reply.started":"2025-01-27T00:45:28.632342Z","shell.execute_reply":"2025-01-27T00:45:28.643077Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:28.644740Z","iopub.execute_input":"2025-01-27T00:45:28.645036Z","iopub.status.idle":"2025-01-27T00:45:28.653662Z","shell.execute_reply.started":"2025-01-27T00:45:28.645013Z","shell.execute_reply":"2025-01-27T00:45:28.652923Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# df = df.drop_duplicates(subset='text')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:28.654657Z","iopub.execute_input":"2025-01-27T00:45:28.654979Z","iopub.status.idle":"2025-01-27T00:45:28.665562Z","shell.execute_reply.started":"2025-01-27T00:45:28.654943Z","shell.execute_reply":"2025-01-27T00:45:28.664773Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# df = df.sample(3000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:28.666522Z","iopub.execute_input":"2025-01-27T00:45:28.666771Z","iopub.status.idle":"2025-01-27T00:45:28.677533Z","shell.execute_reply.started":"2025-01-27T00:45:28.666748Z","shell.execute_reply":"2025-01-27T00:45:28.676763Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"## FINETUNING","metadata":{}},{"cell_type":"code","source":"# !pip install transformers torch evaluate peft","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:28.678673Z","iopub.execute_input":"2025-01-27T00:45:28.679404Z","iopub.status.idle":"2025-01-27T00:45:28.688575Z","shell.execute_reply.started":"2025-01-27T00:45:28.679366Z","shell.execute_reply":"2025-01-27T00:45:28.687821Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# import torch\n# from torch.utils.data import DataLoader, Dataset\n# import torch.nn.functional as F\n# from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n# from sklearn.model_selection import train_test_split\n# import numpy as np\n# import evaluate\n\n# from peft import PeftModel, PeftConfig, LoraConfig, get_peft_model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:28.689531Z","iopub.execute_input":"2025-01-27T00:45:28.689792Z","iopub.status.idle":"2025-01-27T00:45:28.700184Z","shell.execute_reply.started":"2025-01-27T00:45:28.689743Z","shell.execute_reply":"2025-01-27T00:45:28.699522Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# model_path = 'bert-base-uncased'\n\n\n# id2label_={0: \"NOT-PHISHING\", 1: \"PHISHING\"}\n# label2id_={\"NOT-PHISHING\": 0, \"PHISHING\":1}\n\n# model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=2,id2label=id2label_,label2id=label2id_)\n# tokenizer = AutoTokenizer.from_pretrained(model_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:28.701076Z","iopub.execute_input":"2025-01-27T00:45:28.701310Z","iopub.status.idle":"2025-01-27T00:45:28.712658Z","shell.execute_reply.started":"2025-01-27T00:45:28.701286Z","shell.execute_reply":"2025-01-27T00:45:28.712096Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"## custom class","metadata":{"execution":{"iopub.status.busy":"2024-12-15T10:30:36.678352Z","iopub.execute_input":"2024-12-15T10:30:36.678744Z","iopub.status.idle":"2024-12-15T10:30:36.684499Z","shell.execute_reply.started":"2024-12-15T10:30:36.678711Z","shell.execute_reply":"2024-12-15T10:30:36.682969Z"}}},{"cell_type":"code","source":"# class PhishingDataset(Dataset):\n\n#     def __init__(self,texts,lables,tokenizer,max_length=256):\n#         self.texts = texts\n#         self.labels = labels\n#         self.tokenizer = tokenizer\n#         self.max_length = max_length\n\n\n#     def __len__(self):\n#         return len(self.texts)\n\n#     def __getitem__(self,idx):\n#         text = self.texts[idx]\n#         label = self.labels[idx]\n\n#         encoding = self.tokenizer.encode_plus(\n#             text,\n#             add_special_tokens=True,\n#             max_length=self.max_length,\n#             padding='max_length',\n#             truncation=True,\n#             return_tensors='pt'\n#         )\n\n#         return {\n#             'input_ids': encoding['input_ids'].flatten(),\n#             'attention_mask': encoding['attention_mask'].flatten(),\n#             'labels':  torch.tensor(label) \n#         }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:28.713679Z","iopub.execute_input":"2025-01-27T00:45:28.714071Z","iopub.status.idle":"2025-01-27T00:45:28.722344Z","shell.execute_reply.started":"2025-01-27T00:45:28.714046Z","shell.execute_reply":"2025-01-27T00:45:28.721771Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"## dataset creations","metadata":{}},{"cell_type":"code","source":"# texts = df['text'].tolist()\n# labels = df['label'].tolist()\n\n\n\n# #spliting train 80% test 10% val 10%\n# train_texts, temp_texts, train_labels, temp_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)\n# val_texts, test_texts, val_labels, test_labels = train_test_split(temp_texts, temp_labels, test_size=0.5, random_state=42)\n\n# #creating datasetclass\n# train_dataset = PhishingDataset(train_texts, train_labels, tokenizer, max_length=256)\n# val_dataset = PhishingDataset(val_texts, val_labels, tokenizer, max_length=256)\n# test_dataset = PhishingDataset(test_texts, test_labels, tokenizer, max_length=256)\n\n# #creating batches = 32\n# # train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n# # val_dataloader = DataLoader(val_dataset, batch_size=32)\n# # test_dataloader = DataLoader(test_dataset, batch_size=32)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:28.723209Z","iopub.execute_input":"2025-01-27T00:45:28.723444Z","iopub.status.idle":"2025-01-27T00:45:28.732724Z","shell.execute_reply.started":"2025-01-27T00:45:28.723420Z","shell.execute_reply":"2025-01-27T00:45:28.731912Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# accuracy = evaluate.load(\"accuracy\")\n# auc_score = evaluate.load(\"roc_auc\")\n# f1 = evaluate.load('f1')\n# precision = evaluate.load('precision')\n# recall = evaluate.load('recall')\n\n\n# def compute_softmax(logits):\n#     e_x = np.exp(logits - np.max(logits, axis=1, keepdims=True))\n#     softmax_predictions = e_x / e_x.sum(axis=1, keepdims=True)\n#     return softmax_predictions\n\n# def compute_metrics(pred):\n#     logits, labels = pred\n\n#     probabilities = compute_softmax(logits)\n#     positive_class_probs = probabilities[: , 1]\n#     auc_ = np.round(auc_score.compute(prediction_scores=positive_class_probs, references=labels)['roc_auc'], 3)\n\n    \n#     predictions = np.argmax(probabilities, axis=1)\n#     accuracy_ = np.round(accuracy.compute(predictions=predictions, references=labels)['accuracy'], 3)\n#     f1_ = np.round(f1.compute(predictions=predictions, references=labels)['f1'], 3)\n#     precision_ = np.round(precision.compute(predictions=predictions, references=labels)['precision'], 3)\n#     recall_ = np.round(recall.compute(predictions=predictions, references=labels)['recall'], 3)\n\n#     return {\n#         'accuracy': accuracy_,\n#         'f1': f1_,\n#         'auc': auc_,\n#         'precision': precision_,\n#         'recall': recall_\n#     }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:28.733959Z","iopub.execute_input":"2025-01-27T00:45:28.734569Z","iopub.status.idle":"2025-01-27T00:45:28.746201Z","shell.execute_reply.started":"2025-01-27T00:45:28.734524Z","shell.execute_reply":"2025-01-27T00:45:28.745531Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# ## Freezing all but pooler layers params\n\n# #freezing\n# for name, params in model.base_model.named_parameters():\n#     params.requires_grade = False\n\n# #unfreezing\n# for name, params in model.base_model.named_parameters():\n#     if \"pooler\" in name:\n#         params.requires_grade = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:28.747027Z","iopub.execute_input":"2025-01-27T00:45:28.747222Z","iopub.status.idle":"2025-01-27T00:45:28.762184Z","shell.execute_reply.started":"2025-01-27T00:45:28.747201Z","shell.execute_reply":"2025-01-27T00:45:28.761463Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# # import torch_xla.core.xla_model as xm\n# batch_size = 32\n# epochs = 5\n# lr = 2e-5\n\n# # Check if GPU is available\n# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# # If using CPU, switch to TPU device\n# # if device == \"cpu\":\n# #     device = xm.xla_device()  \n\n# if device == 'cpu':\n#     raise ValueError('CPU is getting selected not recommended')\n\n# model.to(device)\n# print(f\"Model is running on: {device}\")\n\n\n# training_args = TrainingArguments(\n#     output_dir='./results',\n#     run_name='subset_train',\n#     num_train_epochs = epochs,\n#     per_device_train_batch_size=batch_size,  \n#     per_device_eval_batch_size=8,\n#     learning_rate= lr,               \n#     logging_strategy= \"epoch\",\n#     eval_strategy=\"epoch\",  \n#     save_strategy= \"epoch\",\n#     # gradient_accumulation_steps=4,\n#     load_best_model_at_end = True,\n    \n# )\n\n# trainer = Trainer(\n#     model = model,\n#     args = training_args,\n#     tokenizer = tokenizer,\n#     train_dataset=train_dataset,\n#     eval_dataset=val_dataset,\n#     compute_metrics=compute_metrics\n    \n# )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:28.766460Z","iopub.execute_input":"2025-01-27T00:45:28.766677Z","iopub.status.idle":"2025-01-27T00:45:28.773342Z","shell.execute_reply.started":"2025-01-27T00:45:28.766655Z","shell.execute_reply":"2025-01-27T00:45:28.772675Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# import time\n\n# t1 = time.time()\n# trainer.train()\n# t2 = time.time()\n\n# time_taken_minutes = round((t2 - t1) / 60, 2)\n# time_taken_hours = round(time_taken_minutes / 60, 2)\n\n# print(f\"Tuning Time: {time_taken_hours} hours\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:28.774198Z","iopub.execute_input":"2025-01-27T00:45:28.774425Z","iopub.status.idle":"2025-01-27T00:45:28.786617Z","shell.execute_reply.started":"2025-01-27T00:45:28.774402Z","shell.execute_reply":"2025-01-27T00:45:28.785833Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# data_subset['label'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:28.787621Z","iopub.execute_input":"2025-01-27T00:45:28.787901Z","iopub.status.idle":"2025-01-27T00:45:28.794896Z","shell.execute_reply.started":"2025-01-27T00:45:28.787864Z","shell.execute_reply":"2025-01-27T00:45:28.794121Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# model.save_pretrained('./saved_model')\n# tokenizer.save_pretrained('./saved_model')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:28.795842Z","iopub.execute_input":"2025-01-27T00:45:28.796077Z","iopub.status.idle":"2025-01-27T00:45:28.804000Z","shell.execute_reply.started":"2025-01-27T00:45:28.796054Z","shell.execute_reply":"2025-01-27T00:45:28.803303Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# from transformers import pipeline\n\n# phishing_pipe = pipeline('text-classification', model=model, tokenizer=tokenizer)\n\n# def predict_phishing(text):\n#     result = phishing_pipe(text)\n#     # print(result)\n#     return result[0]['label'], result[0]['score']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:28.804952Z","iopub.execute_input":"2025-01-27T00:45:28.805215Z","iopub.status.idle":"2025-01-27T00:45:28.812957Z","shell.execute_reply.started":"2025-01-27T00:45:28.805179Z","shell.execute_reply":"2025-01-27T00:45:28.812119Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"# pred = trainer.predict(test_dataset)\n\n# compute_metrics((pred.predictions,pred.label_ids))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:28.813911Z","iopub.execute_input":"2025-01-27T00:45:28.814153Z","iopub.status.idle":"2025-01-27T00:45:28.822280Z","shell.execute_reply.started":"2025-01-27T00:45:28.814129Z","shell.execute_reply":"2025-01-27T00:45:28.821664Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"# for i in len(df):\n#     result = predict_phishing(df.iloc[i]['text'])\n#     if res    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:28.823327Z","iopub.execute_input":"2025-01-27T00:45:28.823801Z","iopub.status.idle":"2025-01-27T00:45:28.832491Z","shell.execute_reply.started":"2025-01-27T00:45:28.823754Z","shell.execute_reply":"2025-01-27T00:45:28.831843Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":" # predict_phishing(df.iloc[4]['text'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:28.833381Z","iopub.execute_input":"2025-01-27T00:45:28.833601Z","iopub.status.idle":"2025-01-27T00:45:28.841377Z","shell.execute_reply.started":"2025-01-27T00:45:28.833578Z","shell.execute_reply":"2025-01-27T00:45:28.840451Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"# import shutil\n\n# # Path to the folder where the model is saved\n# model_folder = './saved_model'\n\n# # Create a zip file for the folder\n# shutil.make_archive('saved_model', 'zip', model_folder)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:28.842457Z","iopub.execute_input":"2025-01-27T00:45:28.842710Z","iopub.status.idle":"2025-01-27T00:45:28.850771Z","shell.execute_reply.started":"2025-01-27T00:45:28.842687Z","shell.execute_reply":"2025-01-27T00:45:28.850006Z"}},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":"# OTHER WAY","metadata":{}},{"cell_type":"code","source":"pip install tensorflow tensorflow-addons","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:28.851633Z","iopub.execute_input":"2025-01-27T00:45:28.851887Z","iopub.status.idle":"2025-01-27T00:45:38.546967Z","shell.execute_reply.started":"2025-01-27T00:45:28.851863Z","shell.execute_reply":"2025-01-27T00:45:38.545968Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.16.1)\nCollecting tensorflow-addons\n  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (24.3.25)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=3.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.11.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (18.1.1)\nRequirement already satisfied: ml-dtypes~=0.3.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.3.2)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.32.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (70.0.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.12.2)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.62.2)\nRequirement already satisfied: tensorboard<2.17,>=2.16 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.16.2)\nRequirement already satisfied: keras>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.3)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.37.0)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.26.4)\nCollecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\nRequirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (2.18.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\nDownloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\nInstalling collected packages: typeguard, tensorflow-addons\n  Attempting uninstall: typeguard\n    Found existing installation: typeguard 4.3.0\n    Uninstalling typeguard-4.3.0:\n      Successfully uninstalled typeguard-4.3.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\nydata-profiling 4.10.0 requires typeguard<5,>=3, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport re\nimport math\nimport time\nimport shutil\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:38.548403Z","iopub.execute_input":"2025-01-27T00:45:38.548691Z","iopub.status.idle":"2025-01-27T00:45:39.223846Z","shell.execute_reply.started":"2025-01-27T00:45:38.548662Z","shell.execute_reply":"2025-01-27T00:45:39.223205Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"# df = pd.read_csv('/kaggle/input/modified-dataset/modified_dataset.csv')\ndf = pd.read_csv('/kaggle/input/ready-for-tuning/ready_for_tuning.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:39.224789Z","iopub.execute_input":"2025-01-27T00:45:39.225103Z","iopub.status.idle":"2025-01-27T00:45:42.829167Z","shell.execute_reply.started":"2025-01-27T00:45:39.225077Z","shell.execute_reply":"2025-01-27T00:45:42.828231Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"# df[df['is_english'] == True]\n# df.drop(columns = ['is_english'],inplace=True)\n# df.drop_duplicates(inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:42.830377Z","iopub.execute_input":"2025-01-27T00:45:42.830642Z","iopub.status.idle":"2025-01-27T00:45:42.834603Z","shell.execute_reply.started":"2025-01-27T00:45:42.830615Z","shell.execute_reply":"2025-01-27T00:45:42.833792Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"# (df['label'].value_counts()/df.shape[0]) * 100","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:42.838289Z","iopub.execute_input":"2025-01-27T00:45:42.838724Z","iopub.status.idle":"2025-01-27T00:45:42.845957Z","shell.execute_reply.started":"2025-01-27T00:45:42.838698Z","shell.execute_reply":"2025-01-27T00:45:42.845307Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"# df['length'] = df['text'].str.len()\n# df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:42.846760Z","iopub.execute_input":"2025-01-27T00:45:42.846980Z","iopub.status.idle":"2025-01-27T00:45:42.857610Z","shell.execute_reply.started":"2025-01-27T00:45:42.846958Z","shell.execute_reply":"2025-01-27T00:45:42.856900Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"# plt.hist(df['length'])\n# plt.title('Word length Histogram')\n# plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:42.858597Z","iopub.execute_input":"2025-01-27T00:45:42.859221Z","iopub.status.idle":"2025-01-27T00:45:42.869194Z","shell.execute_reply.started":"2025-01-27T00:45:42.859184Z","shell.execute_reply":"2025-01-27T00:45:42.868527Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"# sns.histplot(df['length'],kde=True)\n# plt.title('Word length Histogram (KDE)')\n# plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:42.870108Z","iopub.execute_input":"2025-01-27T00:45:42.870424Z","iopub.status.idle":"2025-01-27T00:45:42.879587Z","shell.execute_reply.started":"2025-01-27T00:45:42.870384Z","shell.execute_reply":"2025-01-27T00:45:42.878836Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"# df['length'].min(), df['length'].median(), df['length'].max()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:42.880477Z","iopub.execute_input":"2025-01-27T00:45:42.880684Z","iopub.status.idle":"2025-01-27T00:45:42.889644Z","shell.execute_reply.started":"2025-01-27T00:45:42.880662Z","shell.execute_reply":"2025-01-27T00:45:42.889021Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def clean_email_text(text):\n    text = text.lower()\n\n    #remove re:\n    text = re.sub(r're:','',text,flags=re.IGNORECASE)\n    \n    # htmltags\n    text = re.sub(r'<.*?>', '', text, flags=re.IGNORECASE)\n    #url\n    text = re.sub(r'http[s]?://\\S+|www\\.\\S+|/[\\w/.-]+', '<link>', text, flags=re.IGNORECASE)\n    \n    #email\n    text = text.replace('[@]', '@').replace('[dot]', '.',)\n    text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', '<email>', text, flags=re.IGNORECASE)\n    \n    # signoff\n    text = re.sub(r'\\b(best regards|regards|sincerely|thank you|kind regards|warm regards|best wishes|yours truly|yours sincerely|with appreciation|respectfully|have a great day|until next time|peace),[\\s\\S]*$', '', text, flags=re.IGNORECASE)\n    \n    #removing everything but alphanumeric..\n    # text = re.sub(r'[^a-zA-Z0-9\\s.,]|<link>|<email>', '', text)\n    # text = re.sub(r'(?!(<link>|<email>))[^a-zA-Z0-9\\s.,]', '', text, flags=re.IGNORECASE)\n\n    text = re.sub('<link>','linkplaceholder',text, flags=re.IGNORECASE)\n    text = re.sub('<email>','emailplaceholder',text, flags=re.IGNORECASE)\n    \n    text = re.sub(r'[^a-zA-Z0-9\\s.,]', '', text, flags=re.IGNORECASE)\n    \n    text = re.sub('linkplaceholder','<link>',text, flags=re.IGNORECASE)\n    text = re.sub('emailplaceholder','<email>',text, flags=re.IGNORECASE)\n\n\n    \n    #removing whitespaces\n    text = re.sub(r'\\s+', ' ', text, flags=re.IGNORECASE).strip()\n    \n\n    return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:42.890516Z","iopub.execute_input":"2025-01-27T00:45:42.890746Z","iopub.status.idle":"2025-01-27T00:45:42.902928Z","shell.execute_reply.started":"2025-01-27T00:45:42.890722Z","shell.execute_reply":"2025-01-27T00:45:42.902117Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"# df['text'] = df['text'].apply(clean_email_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:42.903816Z","iopub.execute_input":"2025-01-27T00:45:42.904052Z","iopub.status.idle":"2025-01-27T00:45:42.916552Z","shell.execute_reply.started":"2025-01-27T00:45:42.904029Z","shell.execute_reply":"2025-01-27T00:45:42.915830Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"# df['after_len'] = df['text'].str.len()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:42.917348Z","iopub.execute_input":"2025-01-27T00:45:42.917578Z","iopub.status.idle":"2025-01-27T00:45:42.927155Z","shell.execute_reply.started":"2025-01-27T00:45:42.917555Z","shell.execute_reply":"2025-01-27T00:45:42.926513Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"# df.reset_index(inplace=True,drop=True)\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:42.927962Z","iopub.execute_input":"2025-01-27T00:45:42.928184Z","iopub.status.idle":"2025-01-27T00:45:42.954814Z","shell.execute_reply.started":"2025-01-27T00:45:42.928162Z","shell.execute_reply":"2025-01-27T00:45:42.954082Z"}},"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"         index                                               text  label  \\\n0            0  never agree to be a loser buck up, your troubl...      1   \n1            1  befriend jenna jameson upgrade your sex and pl...      1   \n2            2  cnn.com daily top 10 the daily top 10 from cnn...      1   \n3            3  svn commit r619753 in <link> lib<link> lib<lin...      0   \n4            4  specialpricespharmmoreinfo welcomefastshipping...      1   \n...        ...                                                ...    ...   \n129381  136825  mhln all major designer replica watches vip re...      1   \n129382  136827  the reply for your request for a job place let...      1   \n129383  136828  r me again, about the horrible documentation o...      0   \n129384  136829  r rodbc problem hello, as i wrote i call sqlfe...      0   \n129385  136830  i wanted the desk at his own laws of the. but ...      1   \n\n        length  after_len  \n0          299        280  \n1          105         82  \n2         3939       1605  \n3        24569      12242  \n4          202         68  \n...        ...        ...  \n129381     706        664  \n129382    4957       2076  \n129383    2605       1614  \n129384    2215        170  \n129385    3111       2593  \n\n[129386 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>text</th>\n      <th>label</th>\n      <th>length</th>\n      <th>after_len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>never agree to be a loser buck up, your troubl...</td>\n      <td>1</td>\n      <td>299</td>\n      <td>280</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>befriend jenna jameson upgrade your sex and pl...</td>\n      <td>1</td>\n      <td>105</td>\n      <td>82</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>cnn.com daily top 10 the daily top 10 from cnn...</td>\n      <td>1</td>\n      <td>3939</td>\n      <td>1605</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>svn commit r619753 in &lt;link&gt; lib&lt;link&gt; lib&lt;lin...</td>\n      <td>0</td>\n      <td>24569</td>\n      <td>12242</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>specialpricespharmmoreinfo welcomefastshipping...</td>\n      <td>1</td>\n      <td>202</td>\n      <td>68</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>129381</th>\n      <td>136825</td>\n      <td>mhln all major designer replica watches vip re...</td>\n      <td>1</td>\n      <td>706</td>\n      <td>664</td>\n    </tr>\n    <tr>\n      <th>129382</th>\n      <td>136827</td>\n      <td>the reply for your request for a job place let...</td>\n      <td>1</td>\n      <td>4957</td>\n      <td>2076</td>\n    </tr>\n    <tr>\n      <th>129383</th>\n      <td>136828</td>\n      <td>r me again, about the horrible documentation o...</td>\n      <td>0</td>\n      <td>2605</td>\n      <td>1614</td>\n    </tr>\n    <tr>\n      <th>129384</th>\n      <td>136829</td>\n      <td>r rodbc problem hello, as i wrote i call sqlfe...</td>\n      <td>0</td>\n      <td>2215</td>\n      <td>170</td>\n    </tr>\n    <tr>\n      <th>129385</th>\n      <td>136830</td>\n      <td>i wanted the desk at his own laws of the. but ...</td>\n      <td>1</td>\n      <td>3111</td>\n      <td>2593</td>\n    </tr>\n  </tbody>\n</table>\n<p>129386 rows × 5 columns</p>\n</div>"},"metadata":{}}],"execution_count":46},{"cell_type":"code","source":"df['length'].min(), df['length'].median(), df['length'].max()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:45:42.956091Z","iopub.execute_input":"2025-01-27T00:45:42.956636Z","iopub.status.idle":"2025-01-27T00:45:42.967907Z","shell.execute_reply.started":"2025-01-27T00:45:42.956598Z","shell.execute_reply":"2025-01-27T00:45:42.967108Z"}},"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"(4, 857.0, 4599694)"},"metadata":{}}],"execution_count":47},{"cell_type":"code","source":"# df.iloc[136827]['text']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:47:53.353337Z","iopub.execute_input":"2025-01-27T00:47:53.354158Z","iopub.status.idle":"2025-01-27T00:47:53.357763Z","shell.execute_reply.started":"2025-01-27T00:47:53.354120Z","shell.execute_reply":"2025-01-27T00:47:53.356914Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"# df = df[df['text'] != \"\"]\n# df.drop_duplicates(inplace=True)\n# df.drop_duplicates(subset=['text'],inplace=True)\n# df.reset_index(inplace = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:47:53.374962Z","iopub.execute_input":"2025-01-27T00:47:53.375666Z","iopub.status.idle":"2025-01-27T00:47:53.378586Z","shell.execute_reply.started":"2025-01-27T00:47:53.375638Z","shell.execute_reply":"2025-01-27T00:47:53.377938Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"# (df['label'].value_counts()/df.shape[0])*100","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:47:53.392990Z","iopub.execute_input":"2025-01-27T00:47:53.393484Z","iopub.status.idle":"2025-01-27T00:47:53.396835Z","shell.execute_reply.started":"2025-01-27T00:47:53.393457Z","shell.execute_reply":"2025-01-27T00:47:53.395857Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:47:53.402954Z","iopub.execute_input":"2025-01-27T00:47:53.403387Z","iopub.status.idle":"2025-01-27T00:47:53.414216Z","shell.execute_reply.started":"2025-01-27T00:47:53.403362Z","shell.execute_reply":"2025-01-27T00:47:53.413435Z"}},"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"         index                                               text  label  \\\n0            0  never agree to be a loser buck up, your troubl...      1   \n1            1  befriend jenna jameson upgrade your sex and pl...      1   \n2            2  cnn.com daily top 10 the daily top 10 from cnn...      1   \n3            3  svn commit r619753 in <link> lib<link> lib<lin...      0   \n4            4  specialpricespharmmoreinfo welcomefastshipping...      1   \n...        ...                                                ...    ...   \n129381  136825  mhln all major designer replica watches vip re...      1   \n129382  136827  the reply for your request for a job place let...      1   \n129383  136828  r me again, about the horrible documentation o...      0   \n129384  136829  r rodbc problem hello, as i wrote i call sqlfe...      0   \n129385  136830  i wanted the desk at his own laws of the. but ...      1   \n\n        length  after_len  \n0          299        280  \n1          105         82  \n2         3939       1605  \n3        24569      12242  \n4          202         68  \n...        ...        ...  \n129381     706        664  \n129382    4957       2076  \n129383    2605       1614  \n129384    2215        170  \n129385    3111       2593  \n\n[129386 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>text</th>\n      <th>label</th>\n      <th>length</th>\n      <th>after_len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>never agree to be a loser buck up, your troubl...</td>\n      <td>1</td>\n      <td>299</td>\n      <td>280</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>befriend jenna jameson upgrade your sex and pl...</td>\n      <td>1</td>\n      <td>105</td>\n      <td>82</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>cnn.com daily top 10 the daily top 10 from cnn...</td>\n      <td>1</td>\n      <td>3939</td>\n      <td>1605</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>svn commit r619753 in &lt;link&gt; lib&lt;link&gt; lib&lt;lin...</td>\n      <td>0</td>\n      <td>24569</td>\n      <td>12242</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>specialpricespharmmoreinfo welcomefastshipping...</td>\n      <td>1</td>\n      <td>202</td>\n      <td>68</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>129381</th>\n      <td>136825</td>\n      <td>mhln all major designer replica watches vip re...</td>\n      <td>1</td>\n      <td>706</td>\n      <td>664</td>\n    </tr>\n    <tr>\n      <th>129382</th>\n      <td>136827</td>\n      <td>the reply for your request for a job place let...</td>\n      <td>1</td>\n      <td>4957</td>\n      <td>2076</td>\n    </tr>\n    <tr>\n      <th>129383</th>\n      <td>136828</td>\n      <td>r me again, about the horrible documentation o...</td>\n      <td>0</td>\n      <td>2605</td>\n      <td>1614</td>\n    </tr>\n    <tr>\n      <th>129384</th>\n      <td>136829</td>\n      <td>r rodbc problem hello, as i wrote i call sqlfe...</td>\n      <td>0</td>\n      <td>2215</td>\n      <td>170</td>\n    </tr>\n    <tr>\n      <th>129385</th>\n      <td>136830</td>\n      <td>i wanted the desk at his own laws of the. but ...</td>\n      <td>1</td>\n      <td>3111</td>\n      <td>2593</td>\n    </tr>\n  </tbody>\n</table>\n<p>129386 rows × 5 columns</p>\n</div>"},"metadata":{}}],"execution_count":52},{"cell_type":"markdown","source":"# SETTING UP FOR FINE TUNING","metadata":{}},{"cell_type":"code","source":"!pip install numba ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:47:53.415435Z","iopub.execute_input":"2025-01-27T00:47:53.415669Z","iopub.status.idle":"2025-01-27T00:48:01.560530Z","shell.execute_reply.started":"2025-01-27T00:47:53.415646Z","shell.execute_reply":"2025-01-27T00:48:01.559568Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (0.60.0)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba) (0.43.0)\nRequirement already satisfied: numpy<2.1,>=1.22 in /opt/conda/lib/python3.10/site-packages (from numba) (1.26.4)\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"import tensorflow as tf\nfrom transformers import AutoTokenizer, TFAutoModelForSequenceClassification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom tqdm import tqdm\nfrom tensorflow.keras import metrics\nfrom tensorflow.keras import mixed_precision\n\n# Reset policy to float32\npolicy = mixed_precision.Policy('float32')\nmixed_precision.set_global_policy(policy)\n\n# Verify the policy\nprint(\"Current policy:\", mixed_precision.global_policy())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T09:13:38.579827Z","iopub.execute_input":"2025-01-27T09:13:38.580432Z","iopub.status.idle":"2025-01-27T09:13:55.145740Z","shell.execute_reply.started":"2025-01-27T09:13:38.580395Z","shell.execute_reply":"2025-01-27T09:13:55.144903Z"}},"outputs":[{"name":"stdout","text":"Current policy: <FloatDTypePolicy \"float32\">\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"MODEL_NAME = 'bert-base-uncased'\nBATCH_SIZE = 16\nEPOCHS_PER_BATCH = 3\nMAX_LENGTH = 512\nTOTAL_SAMPLES = len(df)\nBATCH_SAMPLES = 3000\nSAVE_PATH = \"/kaggle/working/bert_phishing/\"\n\nos.makedirs(SAVE_PATH, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:48:16.830976Z","iopub.execute_input":"2025-01-27T00:48:16.831455Z","iopub.status.idle":"2025-01-27T00:48:16.836004Z","shell.execute_reply.started":"2025-01-27T00:48:16.831426Z","shell.execute_reply":"2025-01-27T00:48:16.835092Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"texts = df['text']\nlabels = df['label'].values.astype(np.float32)  # Binary labels (0/1)\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\nmodel = TFAutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:48:16.837622Z","iopub.execute_input":"2025-01-27T00:48:16.837883Z","iopub.status.idle":"2025-01-27T00:48:23.356409Z","shell.execute_reply.started":"2025-01-27T00:48:16.837858Z","shell.execute_reply":"2025-01-27T00:48:23.355711Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6489d0c7455a48edaac6acf4189f319b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50d87c34ec5d4c6da6c2771045d4b7e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f25748f8aec4ab5a8fa1f9535a4bdd6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32fc06deae814d6c996822e8b154f473"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebdbe389f0774b26ba0529c3e35ca415"}},"metadata":{}},{"name":"stderr","text":"All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n\nSome weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"class SafeAUC(tf.keras.metrics.AUC):\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        y_true = tf.cast(y_true, tf.float32)\n        y_pred = tf.cast(y_pred, tf.float32)\n        super().update_state(y_true, y_pred, sample_weight)\n\nclass SafePrecision(tf.keras.metrics.Precision):\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        y_true = tf.cast(y_true, tf.float32)\n        y_pred = tf.cast(y_pred, tf.float32)\n        super().update_state(y_true, y_pred, sample_weight)\n\nclass SafeRecall(tf.keras.metrics.Recall):\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        y_true = tf.cast(y_true, tf.float32)\n        y_pred = tf.cast(y_pred, tf.float32)\n        super().update_state(y_true, y_pred, sample_weight)\n\n\noptimizer = tf.optimizers.Adam(learning_rate=3e-5)\n# optimizer = mixed_precision.LossScaleOptimizer(optimizer)\n\n\nloss = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n\n\n\nmodel.compile(\n    optimizer=optimizer,\n    loss=loss,\n    metrics=[\n        'accuracy',\n    ]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:48:23.357410Z","iopub.execute_input":"2025-01-27T00:48:23.357676Z","iopub.status.idle":"2025-01-27T00:48:23.480168Z","shell.execute_reply.started":"2025-01-27T00:48:23.357649Z","shell.execute_reply":"2025-01-27T00:48:23.479551Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:48:23.481112Z","iopub.execute_input":"2025-01-27T00:48:23.481332Z","iopub.status.idle":"2025-01-27T00:48:23.511069Z","shell.execute_reply.started":"2025-01-27T00:48:23.481309Z","shell.execute_reply":"2025-01-27T00:48:23.510243Z"}},"outputs":[{"name":"stdout","text":"Model: \"tf_bert_for_sequence_classification\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n bert (TFBertMainLayer)      multiple                  109482240 \n                                                                 \n dropout_37 (Dropout)        multiple                  0 (unused)\n                                                                 \n classifier (Dense)          multiple                  769       \n                                                                 \n=================================================================\nTotal params: 109483009 (417.64 MB)\nTrainable params: 109483009 (417.64 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}],"execution_count":58},{"cell_type":"code","source":"def create_stratified_batches(texts, labels, batch_size):\n    # Create a list of indices based on the labels to maintain balance in batches\n    indices_0 = np.where(labels == 0)[0]\n    indices_1 = np.where(labels == 1)[0]\n\n    # Shuffle the indices\n    np.random.shuffle(indices_0)\n    np.random.shuffle(indices_1)\n\n    # Combine indices into balanced batches\n    batch_indices = []\n    for i in range(0, len(indices_0), batch_size // 2):\n        batch_0 = indices_0[i:i + batch_size // 2]\n        batch_1 = indices_1[i:i + batch_size // 2]\n\n        # Combine and shuffle batches to maintain randomness\n        combined_batch = np.concatenate((batch_0, batch_1))\n        np.random.shuffle(combined_batch)\n        batch_indices.append(combined_batch)\n\n    return batch_indices","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:48:23.511902Z","iopub.execute_input":"2025-01-27T00:48:23.512128Z","iopub.status.idle":"2025-01-27T00:48:23.517325Z","shell.execute_reply.started":"2025-01-27T00:48:23.512104Z","shell.execute_reply":"2025-01-27T00:48:23.516522Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"# First split (80% train, 20% temp)\ntrain_texts, temp_texts, train_labels, temp_labels = train_test_split(\n    texts, labels, test_size=0.2, stratify=labels, random_state=42\n)\n\n# Second split (50% of the 20% for test and 50% for validation, i.e., 10% each)\ntest_texts, val_texts, test_labels, val_labels = train_test_split(\n    temp_texts, temp_labels, test_size=0.5, stratify=temp_labels, random_state=42\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:48:23.518393Z","iopub.execute_input":"2025-01-27T00:48:23.518701Z","iopub.status.idle":"2025-01-27T00:48:23.632191Z","shell.execute_reply.started":"2025-01-27T00:48:23.518665Z","shell.execute_reply":"2025-01-27T00:48:23.631572Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"train_batches = create_stratified_batches(train_texts, train_labels, BATCH_SAMPLES)\nval_batches = create_stratified_batches(val_texts, val_labels, BATCH_SAMPLES)\n# test_batches = create_stratified_batches(test_texts, test_labels, BATCH_SAMPLES)\n\nlen(train_batches)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:48:23.633226Z","iopub.execute_input":"2025-01-27T00:48:23.633584Z","iopub.status.idle":"2025-01-27T00:48:23.645154Z","shell.execute_reply.started":"2025-01-27T00:48:23.633541Z","shell.execute_reply":"2025-01-27T00:48:23.644248Z"}},"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"35"},"metadata":{}}],"execution_count":61},{"cell_type":"code","source":"def preprocess_batch(texts_batch, labels_batch):\n    \"\"\"Tokenize and format batch for BERT\"\"\"\n    encodings = tokenizer(\n        texts_batch.tolist(),\n        truncation=True,\n        padding='max_length',\n        max_length=MAX_LENGTH,\n        return_tensors='tf'\n    )\n    return {'input_ids': encodings['input_ids'],\n            'attention_mask': encodings['attention_mask'],\n            'token_type_ids': encodings['token_type_ids']}, labels_batch\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:48:23.647297Z","iopub.execute_input":"2025-01-27T00:48:23.647531Z","iopub.status.idle":"2025-01-27T00:48:23.652256Z","shell.execute_reply.started":"2025-01-27T00:48:23.647506Z","shell.execute_reply":"2025-01-27T00:48:23.651464Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"# Check if GPU is available\ndevice_name = \"/device:GPU:0\"\n\nif tf.config.list_physical_devices('GPU'):\n    print(\"GPU is available\")\nelse:\n    print(\"GPU is not available\")\n    raise ValueError(\"GPU NOT AVAILABLE\")\n\n\n# List all available GPUs\nphysical_devices = tf.config.list_physical_devices('GPU')\n\n\n# Set the first GPU as visible\nif physical_devices:\n    # tf.config.experimental.set_memory_growth(device, True)\n    # tf.config.experimental.get_memory_usage(physical_devices[0])\n\n    tf.config.set_visible_devices(physical_devices[0], 'GPU')  # Use first GPU\nelse:\n    print(\"No GPU detected.\")\n\nphysical_devices","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:48:23.653278Z","iopub.execute_input":"2025-01-27T00:48:23.653617Z","iopub.status.idle":"2025-01-27T00:48:23.663938Z","shell.execute_reply.started":"2025-01-27T00:48:23.653581Z","shell.execute_reply":"2025-01-27T00:48:23.663142Z"}},"outputs":[{"name":"stdout","text":"GPU is available\n","output_type":"stream"},{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"},"metadata":{}}],"execution_count":63},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:48:23.664713Z","iopub.execute_input":"2025-01-27T00:48:23.664985Z","iopub.status.idle":"2025-01-27T00:48:24.775751Z","shell.execute_reply.started":"2025-01-27T00:48:23.664941Z","shell.execute_reply":"2025-01-27T00:48:24.774572Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Mon Jan 27 00:48:24 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   37C    P0             32W /  250W |   15773MiB /  16384MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":64},{"cell_type":"code","source":"# #clears the memory\n\n# from numba import cuda \n# device = cuda.get_current_device()\n# device.reset()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:48:24.777325Z","iopub.execute_input":"2025-01-27T00:48:24.777727Z","iopub.status.idle":"2025-01-27T00:48:24.783064Z","shell.execute_reply.started":"2025-01-27T00:48:24.777677Z","shell.execute_reply":"2025-01-27T00:48:24.782194Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"# Training loop with checkpointing\nbest_val_auc = 0.0  # Track best AUC for saving the best model\nfor i, batch_indices in enumerate(tqdm(train_batches)):\n    # Get current batch\n    a = batch_indices\n    \n    batch_texts = train_texts.iloc[batch_indices]\n    batch_labels = train_labels[batch_indices]\n\n    with tf.device('/GPU:0'):\n        # Preprocess batch\n        X, y = preprocess_batch(batch_texts, batch_labels)\n    \n        # Train on current batch\n        history = model.fit(\n            X,\n            y,\n            epochs=EPOCHS_PER_BATCH, \n            batch_size=BATCH_SIZE, \n            verbose=1\n        )\n      \n    \n    # Save model weights after each batch\n    model.save_weights(f\"{SAVE_PATH}batch_{i+1}_weights.h5\")\n    \n    # Optional: Validate on validation set after every few batches or at the end of each epoch\n    if (i + 1) % 1 == 0:  # Evaluate every 1/2 batch size\n        val_accuracy = []\n        val_loss =[]\n        true_labels = []\n        predicted_probs = []\n        \n        for val_batch in val_batches:\n            val_texts_batch = val_texts.iloc[val_batch]\n            val_labels_batch = val_labels[val_batch]\n            X_val, y_val = preprocess_batch(val_texts_batch, val_labels_batch)\n            \n            # Evaluate accuracy\n            metrics = model.evaluate(X_val, y_val, verbose=0)\n            val_loss.append(metrics[0])  #loss\n            val_accuracy.append(metrics[1])  # accuracy\n            \n            # Get predictions for AUC\n            y_pred = model.predict(X_val, verbose=0)\n            y_pred_probs = tf.sigmoid(y_pred.logits).numpy().flatten()\n            true_labels.extend(val_labels_batch)\n            predicted_probs.extend(y_pred_probs)\n\n        \n        avg_val_accuracy = np.mean(val_accuracy)\n        auc = roc_auc_score(true_labels, predicted_probs)\n\n        # Save best model based on AUC\n        if avg_val_auc > best_val_auc:\n            best_val_auc = avg_val_auc\n            model.save_pretrained(SAVE_PATH + \"best_model\")\n            tokenizer.save_pretrained(SAVE_PATH + \"best_model\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:49:05.812864Z","iopub.execute_input":"2025-01-27T00:49:05.813528Z","iopub.status.idle":"2025-01-27T01:10:01.367702Z","shell.execute_reply.started":"2025-01-27T00:49:05.813493Z","shell.execute_reply":"2025-01-27T01:10:01.366553Z"}},"outputs":[{"name":"stderr","text":"  0%|          | 0/35 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 1/3\nWARNING: AutoGraph could not transform <function infer_framework at 0x7aad6e07a710> and will run it as-is.\nCause: for/else statement not yet supported\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1737939005.568135     109 service.cc:145] XLA service 0x7aad0c3da060 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1737939005.568185     109 service.cc:153]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1737939005.736727     109 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"188/188 [==============================] - 268s 1s/step - loss: 0.5847 - accuracy: 0.7333\nEpoch 2/3\n188/188 [==============================] - 202s 1s/step - loss: 0.3340 - accuracy: 0.8897\nEpoch 3/3\n188/188 [==============================] - 203s 1s/step - loss: 0.2591 - accuracy: 0.9213\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/35 [20:55<?, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[67], line 52\u001b[0m\n\u001b[1;32m     48\u001b[0m     predicted_probs\u001b[38;5;241m.\u001b[39mextend(y_pred_probs)\n\u001b[1;32m     51\u001b[0m avg_val_accuracy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(val_accuracy)\n\u001b[0;32m---> 52\u001b[0m auc \u001b[38;5;241m=\u001b[39m \u001b[43mroc_auc_score\u001b[49m(true_labels, predicted_probs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Save best model based on AUC\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m avg_val_auc \u001b[38;5;241m>\u001b[39m best_val_auc:\n","\u001b[0;31mNameError\u001b[0m: name 'roc_auc_score' is not defined"],"ename":"NameError","evalue":"name 'roc_auc_score' is not defined","output_type":"error"}],"execution_count":67},{"cell_type":"code","source":"# # Optional: Validate on validation set after every few batches or at the end of each epoch\n#     if (i + 1) % 1 == 0:  # Evaluate every 1/2 batch size\n#         val_loss, val_acc, val_auc = [], [], []\n#         for val_batch in val_batches:\n#             val_texts = val_texts.iloc[val_batch]\n#             val_labels = val_labels[val_batch]\n#             X_val, y_val = preprocess_batch(val_texts, val_labels)\n#             metrics = model.evaluate(X_val, y_val, verbose=0)\n#             val_loss.append(metrics[0])\n#             val_acc.append(metrics[1])\n#             val_auc.append(metrics[2])\n        \n#         avg_val_auc = np.mean(val_auc)\n#         print(f\"\\nAfter Batch {i+1}:\")\n#         print(f\"Val Loss: {np.mean(val_loss):.4f}\")\n#         print(f\"Val Acc: {np.mean(val_acc):.4f}\")\n#         print(f\"Val AUC: {avg_val_auc:.4f}\\n\")\n        \n#         # Save best model based on AUC\n#         if avg_val_auc > best_val_auc:\n#             best_val_auc = avg_val_auc\n#             model.save_pretrained(SAVE_PATH + \"best_model\")\n#             tokenizer.save_pretrained(SAVE_PATH + \"best_model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T00:48:26.648631Z","iopub.status.idle":"2025-01-27T00:48:26.648964Z","shell.execute_reply.started":"2025-01-27T00:48:26.648813Z","shell.execute_reply":"2025-01-27T00:48:26.648834Z"}},"outputs":[],"execution_count":null}]}